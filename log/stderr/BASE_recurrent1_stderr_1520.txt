mkdir: cannot create directory ‘./backup/BASE_recurrent1’: File exists
/home/cilab4/anaconda3/envs/ODI/lib/python3.8/site-packages/torchvision/transforms/transforms.py:287: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.
  warnings.warn(
/home/cilab4/anaconda3/envs/ODI/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:129: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
  warnings.warn("Detected call of `lr_scheduler.step()` before `optimizer.step()`. "
/home/cilab4/anaconda3/envs/ODI/lib/python3.8/site-packages/torch/nn/functional.py:4003: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.
  warnings.warn(
Traceback (most recent call last):
  File "train.py", line 47, in <module>
    trainer.train()
  File "/mnt/server4_hard1/heeseon/monodepth2/trainer.py", line 227, in train
    self.run_epoch()
  File "/mnt/server4_hard1/heeseon/monodepth2/trainer.py", line 254, in run_epoch
    outputs, losses = self.process_batch(inputs)
  File "/mnt/server4_hard1/heeseon/monodepth2/trainer.py", line 331, in process_batch
    losses = self.compute_losses(inputs, outputs)
  File "/mnt/server4_hard1/heeseon/monodepth2/trainer.py", line 739, in compute_losses
    smooth_loss = get_smooth_loss(norm_disp, color)
  File "/mnt/server4_hard1/heeseon/monodepth2/layers.py", line 212, in get_smooth_loss
    grad_disp_x *= torch.exp(-grad_img_x)
RuntimeError: The size of tensor a (319) must match the size of tensor b (639) at non-singleton dimension 3
